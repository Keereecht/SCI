# import fitz
# import numpy as np
# import pandas as pd
# from io import BytesIO  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£ import
# from tkinter import filedialog 
# import tkinter as tk
# import data_storage

# def notfoundh(text_info):
#     docf = data_storage.pdf_path  # ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î

#     # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
#     if isinstance(docf, BytesIO):  
#         doc = fitz.open("pdf", docf.getvalue())  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏à‡∏≤‡∏Å memory (BytesIO)
#     else:
#         doc = fitz.open(docf)  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏à‡∏≤‡∏Å path

#     all_words_top = []
#     for page_num in range(len(doc)):
#         page = doc.load_page(data_storage.page_top)  # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
#         words = page.get_text("words")  # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "words"
#         page_words = [word[4] for word in words]  # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥
#         all_words_top.extend(page_words)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°
#     doc.close()

#     all_words_bot = []
#     for page_num in range(len(doc)):
#         page = doc.load_page(data_storage.page_bot)  # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
#         words = page.get_text("words")  # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "words"
#         page_words = [word[4] for word in words]  # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥
#         all_words_bot.extend(page_words)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°
#     doc.close()

#     checktop = data_storage.data_top["Ref_Des"].str.split(',').explode().tolist()
#     checkbot = data_storage.data_buttom["Ref_Des"].str.split(',').explode().tolist()
#     checkhl = data_storage.data_hl_top["Ref_Des"].str.split(',').explode().tolist()

#     all_words = []
#     for page_num in range(len(doc)):
#         page = doc.load_page(page_num)  # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤
#         words = page.get_text("words")  # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö "words"
#         page_words = [word[4] for word in words]  # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥
#         all_words_bot.extend(page_words)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°
#     doc.close()

#     checktop = data_storage.data_top["Ref_Des"].str.split(',').explode().tolist()
#     checkbot = data_storage.data_buttom["Ref_Des"].str.split(',').explode().tolist()
#     checkhl = data_storage.data_hl_top["Ref_Des"].str.split(',').explode().tolist()


#     notfoundtop = set(map(lambda x: x.strip().upper(), set(checktop))) - set(map(lambda x: x.strip().upper(), all_words_top))
#     notfoundbot = set(map(lambda x: x.strip().upper(), set(checkbot))) - set(map(lambda x: x.strip().upper(), all_words_bot))
#     notfoundhl = set(map(lambda x: x.strip().upper(), set(checkhl))) - set(map(lambda x: x.strip().upper(), all_words_bot))

#     print(notfound)

#     data_storage.notfountlist = len(notfound)

#     checknotfound = data_storage.df[["Ref_Des", "Op_Seq"]].to_numpy()
#     expanded_data = []
#     for row in checknotfound:
#         ref_des_list = row[0].split(",")  # ‡πÅ‡∏¢‡∏Å Ref_Des ‡∏î‡πâ‡∏ß‡∏¢ ","
#         for ref_des in ref_des_list:
#             expanded_data.append({"Ref_Des": ref_des.strip(), "Op_Seq": row[1]})
#     expanded_df = pd.DataFrame(expanded_data)
#     filtered_df = expanded_df[expanded_df["Ref_Des"].isin(notfound)]
#     filtered_array = filtered_df.to_numpy()


#     # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç
#     filtered_array[:, 1] = np.where(
#         filtered_array[:, 1].astype(int) == 150, "TOP", 
#         np.where(filtered_array[:, 1].astype(int) == 50, "BOTTOM", 
#         np.where(filtered_array[:, 1].astype(int) > 200, "HANDLOAD", filtered_array[:, 1]))
#     )

#     sorted_filtered_array = filtered_array[
#         np.lexsort((
#             filtered_array[:, 1],  # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° layer
#             np.where(filtered_array[:, 1] == "TOP", 0,  
#                      np.where(filtered_array[:, 1] == "BOTTOM", 1, 2))  
#         ))
#     ]

#     total_count_not = 0
#     count_width = 10
#     value_width = 15
#     result_width = 15
#     count_layer = 15
#     header = f"{'Item'.ljust(count_width)}{'Layer'.ljust(count_layer)}{'Device'.ljust(value_width)}{'actual result'.ljust(result_width)}\n"
    
#     text_info.insert(tk.END, "-" * len(header) + "\n")
#     text_info.insert(tk.END, header)
#     text_info.insert(tk.END, "-" * len(header) + "\n")

#     for notf in sorted_filtered_array:
#         devicenf = notf[0]  
#         layernf = notf[1]   
#         total_count_not += 1
#         formatted_text = (
#             f"{str(total_count_not).ljust(count_width)}"
#             f"{layernf.ljust(count_layer)}"
#             f"{devicenf.ljust(value_width)}"
#             f"{'Not found'.ljust(result_width)}\n"
#         )
#         text_info.insert(tk.END, formatted_text)
    
#     text_info.configure(state="disabled")
import fitz
import numpy as np
import pandas as pd
from io import BytesIO  
import tkinter as tk
import data_storage

def notfoundh(text_info):
    docf = data_storage.pdf_path  # ‡πÑ‡∏ü‡∏•‡πå PDF ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î

    # üîπ ‡πÄ‡∏õ‡∏¥‡∏î PDF ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    if isinstance(docf, BytesIO):  
        doc = fitz.open("pdf", docf.getvalue())  
    else:
        doc = fitz.open(docf)  

    # üîπ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ TOP
    all_words_top = []
    page_top = doc.load_page(data_storage.page_top)
    words_top = page_top.get_text("words")
    all_words_top = [word[4].strip() for word in words_top]  

    # üîπ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ BOT
    all_words_bot = []
    page_bot = doc.load_page(data_storage.page_bot)
    words_bot = page_bot.get_text("words")
    all_words_bot = [word[4].strip() for word in words_bot]  
    all_words_hl = all_words_top + all_words_bot
    doc.close()  # üîπ ‡∏õ‡∏¥‡∏î PDF ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß
    # üîπ ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ Ref_Des ‡∏à‡∏≤‡∏Å DataFrame
    checktop = data_storage.data_top["Ref_Des"].str.split(',').explode().tolist()
    checkbot = data_storage.data_buttom["Ref_Des"].str.split(',').explode().tolist()
    checkhl = data_storage.data_hl_top["Ref_Des"].str.split(',').explode().tolist()

    # üîπ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö
    notfoundtop = set(map(str.upper, map(str.strip, checktop))) - set(map(str.upper, all_words_top))
    notfoundbot = set(map(str.upper, map(str.strip, checkbot))) - set(map(str.upper, all_words_bot))
    notfoundhl = set(map(str.upper, map(str.strip, checkhl))) - set(map(str.upper, all_words_hl))

    print("üîé Not Found (TOP):", notfoundtop)
    print("üîé Not Found (BOTTOM):", notfoundbot)
    print("üîé Not Found (HANDLOAD):", notfoundhl)

    # üîπ ‡∏£‡∏ß‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    notfound = notfoundtop | notfoundbot | notfoundhl  
    data_storage.notfountlist = len(notfound)

    # üîπ ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏à‡∏≤‡∏Å DataFrame
    checknotfound = data_storage.df[["Ref_Des", "Op_Seq"]].to_numpy()
    expanded_data = [
        {"Ref_Des": ref.strip(), "Op_Seq": row[1]}
        for row in checknotfound for ref in row[0].split(",")
    ]

    expanded_df = pd.DataFrame(expanded_data)
    filtered_df = expanded_df[expanded_df["Ref_Des"].isin(notfound)]
    filtered_array = filtered_df.to_numpy()

    # üîπ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏° Layer
    filtered_array[:, 1] = np.where(
        filtered_array[:, 1].astype(int) == 150, "TOP", 
        np.where(filtered_array[:, 1].astype(int) == 50, "BOTTOM", 
        np.where(filtered_array[:, 1].astype(int) > 200, "HANDLOAD", filtered_array[:, 1]))
    )

    # üîπ ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° Layer
    sorted_filtered_array = filtered_array[
        np.lexsort((
            filtered_array[:, 1],  
            np.where(filtered_array[:, 1] == "TOP", 0,  
                     np.where(filtered_array[:, 1] == "BOTTOM", 1, 2))  
        ))
    ]

    # üîπ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÉ‡∏ô Tkinter
    total_count_not = 0
    count_width = 10
    value_width = 15
    result_width = 15
    count_layer = 15
    header = f"{'Item'.ljust(count_width)}{'Layer'.ljust(count_layer)}{'Device'.ljust(value_width)}{'actual result'.ljust(result_width)}\n"
    
    text_info.insert(tk.END, "-" * len(header) + "\n")
    text_info.insert(tk.END, header)
    text_info.insert(tk.END, "-" * len(header) + "\n")

    for notf in sorted_filtered_array:
        devicenf, layernf = notf[0], notf[1]   
        total_count_not += 1
        formatted_text = (
            f"{str(total_count_not).ljust(count_width)}"
            f"{layernf.ljust(count_layer)}"
            f"{devicenf.ljust(value_width)}"
            f"{'Not found'.ljust(result_width)}\n"
        )
        text_info.insert(tk.END, formatted_text)
    
    text_info.configure(state="disabled")
